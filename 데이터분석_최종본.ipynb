{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b98cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pmdarima as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aa6a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\heygu\\과제_파일.xlsx')\n",
    "print(\"Train subset column : {}\".format(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281efac2",
   "metadata": {},
   "source": [
    "## 시간 데이터 변환\n",
    "- 전처리하기 쉽도록 데이터 변환\n",
    "- 월, 년, 주로 분리하여 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e57c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_date'] = pd.to_datetime(df['start_date'], format='%Y-%m-%d %H:%M:%S') # object -> datetime\n",
    "df['start_Year'] = df['start_date'].dt.year # 연\n",
    "df['start_Month'] =df['start_date'].dt.month # 월\n",
    "df['start_Day'] =df['start_date'].dt.day # 일\n",
    "df['strart_WeekOfYear'] = df['start_date'].dt.strftime(\"%W\")\n",
    "df['strart_WeekOfYear'] = pd.to_numeric(df['strart_WeekOfYear'])\n",
    "\n",
    "df['end_date'] = pd.to_datetime(df['end_date'], format='%Y-%m-%d %H:%M:%S') # object -> datetime\n",
    "df['end_Year'] = df['end_date'].dt.year # 연\n",
    "df['end_Month'] =df['end_date'].dt.month # 월\n",
    "df['end_Day'] =df['end_date'].dt.day # 일\n",
    "df['end_WeekOfYear'] = df['end_date'].dt.strftime(\"%W\")\n",
    "df['end_WeekOfYear'] = pd.to_numeric(df['end_WeekOfYear'])\n",
    "\n",
    "df = df.sort_values(by='start_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760bd497",
   "metadata": {},
   "source": [
    "## 결측치 처리 하기\n",
    "- non-null에 값은 동일하다.하지만 그렇다고 결측치가 없다고 할 수 없다.\n",
    "- 형에도 이상이 없다.\n",
    "- 년, 월, 일, 주에 데이터 형식이나 이상값이 있는지 확인하기 (데이터의 범위, 형식 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2387687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca6f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# 결측값 영역 표시\n",
    "msno.matrix(df)\n",
    "plt.show()\n",
    "\n",
    "# 결측값 막대 그래프\n",
    "msno.bar(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4db613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측값이 아닌 빈 문자열이 있는지 확인\n",
    "# 애초에 연속형이라 있을 수가 없음.\n",
    "def is_emptystring(x):\n",
    "    return x.eq('').any()\n",
    " \n",
    "df.apply(lambda x:is_emptystring(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acae92b",
   "metadata": {},
   "source": [
    "### 특성 독립 변수 결측치\n",
    "- revenue 주간 매출\n",
    "- total_active_days 모든 유저의 활성 일수 총합\n",
    "- total_time 모든 유저의 플레이 시간 총합 \n",
    "- average_session_duration 실행시 평균 앱 실행 시간\n",
    "- average_session_per_user 주간 평균 앱 실행 횟수\n",
    "- average_time_per_user 주간 평균 1인당 플레이 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eaa5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#년,월,일,주에 년도가 두자리 라던거 말이 안되는 값이 있는지 확인하기\n",
    "df.start_Year.value_counts()\n",
    "df.end_Year.value_counts()\n",
    "df.start_Month.value_counts()\n",
    "df.start_Day.value_counts()\n",
    "df.end_Week.value_counts()\n",
    "df.start_Week.value_counts()\n",
    "df.end_Month.value_counts()\n",
    "df.end_Day.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c9c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1000이상인 이상한 값 있는지 확인\n",
    "df.product_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7c80dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.average_active_days.value_counts()\n",
    "#df.average_active_users.value_counts()\n",
    "#df.average_session_duration.value_counts()\n",
    "#df.average_time_per_user.value_counts()\n",
    "#df.average_session_per_user.value_counts()\n",
    "\n",
    "#df.download.value_counts()\n",
    "#df.install_base.value_counts()\n",
    "#df.open_rate.value_counts()\n",
    "#df.revenue.value_counts()\n",
    "#df.total_active_days.value_counts()\n",
    "#df.total_time.value_counts()\n",
    "#df.genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e40e1184",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_revence_miss \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevenue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)]\n\u001b[0;32m      2\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_columns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m df_revence_miss\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_revence_miss = df[(df[\"revenue\"] <= 0)]\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_revence_miss\n",
    "len(df_revence_miss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421bfc35",
   "metadata": {},
   "source": [
    "### 변수간 수학적 계산을 통한 결측치 처리\n",
    "\n",
    "### 결측치 대체 기준\n",
    "- 삭제하기에는 값이 일주일치가 사라지는 효과가 생기기에 위험도가 따른다.\n",
    "\n",
    "#### revenue 결측치\n",
    "- 매출이란? 유료서비스나 아이템, 유료 앱등을 구매했을 때 수익이 발생하면서 생기는 것\n",
    "- 정확히 구매자 데이터가 없기 때문에 유저가 플레이만 했는지 구매를 했는지 알수가 없다.\n",
    "- 실질적인 구매가 없었다면 수익은 발생하지 않아서 0 인것이 이해가 된다.\n",
    "- 688개로 아주 많은 양을 차지하고 있다고 느껴지지 않기에 넘어가겠다.\n",
    "- 추후 문제가 될 경우 다시 확인해보기\n",
    "\n",
    "\n",
    "#### 변수간에 수학적 계산을 통해서 처리 하려했으나 비식별화가 되어있어 그러기는 어렵다\n",
    "\n",
    "- 중앙값으로 대체하기\n",
    "\n",
    "- 모두 0인 경우 결측치 아님 그냥 유저가 없었을 뿐이다.<br>\n",
    "\n",
    "- 실행시 평균 앱 실행 시간 : average_time_per_user 주간 평균 1인당 플레이 시간 , total_time 모든 유저의 플레이 시간 총합 \n",
    "\n",
    "- 모든 유저의 활성 일수 총합 : average_active_days 주간 평균 활성 일수, average_session_duration 실행시 평균 앱 실행 시간, average_session_per_user 주간 평균 앱 실행 횟수, average_time_per_user 주간 평균 1인당 플레이 시간\n",
    "\n",
    "- total_time : average_time_per_user 주간 평균 1인당 플레이 시간, average_session_duration 실행시 평균 앱 실행 시간 (한 번 실행 했을 때 평균적으로 플레이하는 시간)\n",
    "\n",
    "- 주간 평균 앱 실행 횟수 : average_time_per_user 주간 평균 1인당 플레이 시간, total_time 모든 유저의 플레이 시간 총합, average_session_duration 실행시 평균 앱 실행 시간 (한 번 실행 했을 때 평균적으로 플레이하는 시간),\n",
    "\n",
    "- 주간 평균 1인당 플레이 시간 : average_time_per_user 주간 평균 1인당 플레이 시간, total_time 모든 유저의 플레이 시간 총합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158e7357",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(0,54609):\n",
    "    if df.loc[num ,\"average_time_per_user\"] == 0 :\n",
    "        if ((df.loc[num ,\"total_time\"] > 0) | (df.loc[num ,\"average_session_duration\"] > 0)):\n",
    "            df_new = df[df.loc[num, \"product_id\"] == df['product_id']]\n",
    "            df.loc[num ,\"average_time_per_user\"] = df_new[\"average_time_per_user\"].median()\n",
    "            \n",
    "    if df.loc[num ,\"average_session_per_user\"] == 0:\n",
    "        if((df.loc[num ,\"total_time\"] > 0) | (df.loc[num ,\"average_session_duration\"] > 0)):\n",
    "            df_new = df[df.loc[num, \"product_id\"] == df['product_id']]\n",
    "            df.loc[num ,\"average_session_per_user\"] = df_new[\"average_session_per_user\"].median()\n",
    "            \n",
    "    if df.loc[num ,\"average_session_duration\"] == 0:\n",
    "        if((df.loc[num ,\"total_time\"] > 0) | (df.loc[num ,\"average_session_per_user\"] > 0)):\n",
    "            df_new = df[df.loc[num, \"product_id\"] == df['product_id']]\n",
    "            df.loc[num ,\"average_session_duration\"] = df_new[\"average_session_duration\"].median()\n",
    "            \n",
    "    if df.loc[num ,\"total_time\"] == 0:\n",
    "        if ((df.loc[num ,\"average_session_duration\"] > 0) | (df.loc[num ,\"average_session_per_user\"] > 0 )| (df.loc[num ,\"average_time_per_user\"] > 0)):\n",
    "            df_new = df[df.loc[num, \"product_id\"] == df['product_id']]\n",
    "            df.loc[num ,\"total_time\"] = df_new[\"total_time\"].median()\n",
    "            \n",
    "    if df.loc[num ,\"total_active_days\"] == 0:\n",
    "        if (df.loc[num ,\"average_active_days\"] > 0):\n",
    "            df_new = df[df.loc[num, \"product_id\"] == df['product_id']]\n",
    "            df.loc[num ,\"average_active_days\"] = df_new[\"average_active_days\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25c1e07",
   "metadata": {},
   "source": [
    "### 비식별화로 인해 제외된 산술계산 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a8f855",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(0,54609):\n",
    "    if (df.loc[num ,\"average_time_per_user\"] == 0):\n",
    "        if((df.loc[num ,\"total_time\"] > 0) & (df.loc[num ,\"average_session_duration\"] > 0)):\n",
    "            print(df.loc[num ,\"total_time\"], df.loc[num ,\"average_active_users\"])\n",
    "            value1 = (df.loc[num ,\"total_time\"]/df.loc[num ,\"average_session_duration\"])/7\n",
    "        #value2 = df.loc[num ,\"open_rate\"]*df.loc[num, \"install_base\"]*(df.loc[num ,\"average_time_per_user\"]*7)\n",
    "        #value3 = (df.loc[num ,\"average_active_users\"]*7)*(df.loc[num ,\"average_time_per_user\"]*7)\n",
    "        if value1 > 0:\n",
    "            df.loc[num, \"average_session_per_user\"] = value1\n",
    "            value1 = 0\n",
    "      #  elif value2 > 0:\n",
    "      #      df.loc[num, \"total_time\"] = value2\n",
    "      #  elif value3 > 0:\n",
    "      #      df.loc[num, \"total_time\"] = value3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b943e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(0,54609):\n",
    "    if (df.loc[num ,\"average_session_per_user\"] == 0):\n",
    "        if((df.loc[num ,\"total_time\"] > 0) & (df.loc[num ,\"average_session_duration\"] > 0)):\n",
    "            print(df.loc[num ,\"total_time\"], df.loc[num ,\"average_session_duration\"])\n",
    "            value1 = df.loc[num ,\"total_time\"]/(df.loc[num ,\"average_session_duration\"])\n",
    "        #value2 = df.loc[num ,\"open_rate\"]*df.loc[num, \"install_base\"]*(df.loc[num ,\"average_time_per_user\"]*7)\n",
    "        #value3 = (df.loc[num ,\"average_active_users\"]*7)*(df.loc[num ,\"average_time_per_user\"]*7)\n",
    "        if value1 > 0:\n",
    "            df.loc[num, \"average_session_per_user\"] = value1\n",
    "            value1 = 0\n",
    "      #  elif value2 > 0:\n",
    "      #      df.loc[num, \"total_time\"] = value2\n",
    "      #  elif value3 > 0:\n",
    "      #      df.loc[num, \"total_time\"] = value3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe4472",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(0,54609):\n",
    "    if (df.loc[num ,\"average_session_duration\"] == 0):\n",
    "        if((df.loc[num ,\"total_time\"] > 0) & (df.loc[num ,\"average_session_per_user\"] > 0)):\n",
    "            print(df.loc[num ,\"total_time\"], df.loc[num ,\"average_session_per_user\"])\n",
    "            value1 = df.loc[num ,\"total_time\"]/(df.loc[num ,\"average_session_per_user\"]*7)\n",
    "        #value2 = df.loc[num ,\"open_rate\"]*df.loc[num, \"install_base\"]*(df.loc[num ,\"average_time_per_user\"]*7)\n",
    "        #value3 = (df.loc[num ,\"average_active_users\"]*7)*(df.loc[num ,\"average_time_per_user\"]*7)\n",
    "        if value1 > 0:\n",
    "            df.loc[num, \"average_session_duration\"] = value1\n",
    "            value1 = 0\n",
    "      #  elif value2 > 0:\n",
    "      #      df.loc[num, \"total_time\"] = value2\n",
    "      #  elif value3 > 0:\n",
    "      #      df.loc[num, \"total_time\"] = value3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e924a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(0,54609):\n",
    "    if (df.loc[num ,\"total_time\"] == 0):\n",
    "        value1 = df.loc[num ,\"average_session_duration\"]*(df.loc[num ,\"average_session_per_user\"]*7)\n",
    "        value2 = df.loc[num ,\"open_rate\"]*df.loc[num, \"install_base\"]*(df.loc[num ,\"average_time_per_user\"]*7)\n",
    "        value3 = (df.loc[num ,\"average_active_users\"]*7)*(df.loc[num ,\"average_time_per_user\"]*7)\n",
    "        if value1 > 0:\n",
    "            df.loc[num, \"total_time\"] = value1\n",
    "            value1 = 0\n",
    "        elif value2 > 0:\n",
    "            df.loc[num, \"total_time\"] = value2\n",
    "            value2 = 0\n",
    "        elif value3 > 0:\n",
    "            df.loc[num, \"total_time\"] = value3\n",
    "            value3 = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb8aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(0,54609):\n",
    "    if (df.loc[num ,\"total_active_days\"] == 0):\n",
    "        value1 = df.loc[num ,\"average_active_days\"]*7\n",
    "        value2 = df.loc[num ,\"open_rate\"]*df.loc[num, \"install_base\"]\n",
    "        #print(df.loc[[num]][\"average_active_days\"], value1, value2)\n",
    "        if value1 > 0:\n",
    "            df.loc[num, \"total_active_days\"] = value1\n",
    "            value1 = 0\n",
    "        elif value2 > 0:\n",
    "            df.loc[num, \"total_active_days\"] = value2\n",
    "            value2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43900e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_active_days_miss = df[(df[\"total_active_days\"] <= 0)]\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "df_total_active_days_miss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49a862e",
   "metadata": {},
   "source": [
    "### 기간 행 결측치 발견\n",
    "- 이전 년도가 없거나 \n",
    "- 몇 달이 없거나 한 경우가 너무 많음\n",
    "- 104개여야함 \n",
    "- 추세적으로 비슷한 애들을 묶은 후에 값을 채워줄 필요가 있음 그렇지 않으면 지점별로 데이터가 부족해서 다음 값을 특정할 수가 없다.\n",
    "- 게다가 가장 긴게 92개이다.\n",
    "- df[df[\"product_id\"]==185]처럼 심각하게 1개 혹은 2개 밖에 값이 없는 경우도 있다.\n",
    "\n",
    "##### 해결 방식\n",
    "- 그룹화하여 그룹화된 애들의 중앙값으로 만들어 버릴 예정\n",
    "- 단, 너무 많은 결측치가 존재하는 경우 이는 메우지 않는다.\n",
    "- 시계열은 없는 시간대를 만든다는게 쉽지 않기에 클러스터링 할때만 사용해서 혹여 잘못 훈련하는 상황을 방지 하겠다.\n",
    "- 2021,2022이 추세가 다른다. 년도는 이어지듯이 매출이 달라진다.\n",
    "- 되도록 많은 데이터로 해당 추세를 예측하려고 해야한다. \n",
    "- 시간에 따라서 일정한 매출을 가지지는 않아보인다. 상당히 튀는 값을 가진다.\n",
    "- 그 다음년도까지 확실히 영향을 주는걸 연도별 비교로 확인 했음\n",
    "- 심각하게 손실된 제품은 값을 제거해주고 차라리 다른 애들을 추론한 중앙값으로 대체하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a8d381e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m storeset \u001b[38;5;241m=\u001b[39m df[df\u001b[38;5;241m.\u001b[39mproduct_id \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m50\u001b[39m]\n\u001b[0;32m      2\u001b[0m storeset\u001b[38;5;241m.\u001b[39mcount()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(30,60))\n",
    "\n",
    "for store in range(0,50):\n",
    "    storeset = df[df.product_id ==store]\n",
    "    storeset_2021 = storeset[storeset.start_Year==2021]\n",
    "    storeset_2022 = storeset[storeset.start_Year==2022]\n",
    "    \n",
    "    ax = fig.add_subplot(12,5, store + 1)\n",
    "    \n",
    "    plt.title(f\"store_{store}\")\n",
    "    ax.plot(storeset_2021.end_WeekOfYear, storeset_2021.revenue, label=\"2021\", alpha=0.3)\n",
    "    ax.plot(storeset_2022.end_WeekOfYear, storeset_2022.revenue, label=\"2022\", alpha=0.3)\n",
    "    ax.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c95188",
   "metadata": {},
   "source": [
    "### 각 게임별 연도별 매출 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe5bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30,60))\n",
    "\n",
    "for store in range(0,50):\n",
    "    storeset = df[df.product_id ==store]\n",
    "    storeset_2021 = storeset[storeset.start_Year==2021]\n",
    "    storeset_2022 = storeset[storeset.start_Year==2022]\n",
    "    \n",
    "    ax = fig.add_subplot(12,5, store + 1)\n",
    "    \n",
    "    plt.title(f\"store_{store}\")\n",
    "    ax.plot(storeset_2021.end_WeekOfYear, storeset_2021.revenue, label=\"2021\", alpha=0.3)\n",
    "    ax.plot(storeset_2022.end_WeekOfYear, storeset_2022.revenue, label=\"2022\", alpha=0.3)\n",
    "    ax.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ef5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(columns = df.columns)\n",
    "for num in range(0,1000):\n",
    "    co = df[(df[\"product_id\"] == num)]\n",
    "    size = co.count()\n",
    "    if size.start_date == 92:\n",
    "        print(co.count(), num)\n",
    "        df2 = pd.concat([df2,co], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a630da22",
   "metadata": {},
   "source": [
    "# 게임별 매출 추세 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72b25f7",
   "metadata": {},
   "source": [
    "- 잘 보면 일정하게 급격하게 치솟다가 하강하는 그래프들이 종종 보이는데 모바일 게임일 확률이 높다. 모바일 게임의 경우 게임 출시 초반에 매출이 가장 높고 그 이후에는 점차 감소하게 됩니다\n",
    "\n",
    "- 게임별 매출 추세가 상당히 다르기 때문에 평균이나 총합으로 처리하면 안될 것 같다.\n",
    "- 개별적이나 그룹화가 필요하다.\n",
    "\n",
    "* 게임 특성별로 묶으면 모바일, RPG 등으로 보는 편이 좋을 것 같다. 경향성이 비슷한 게임끼리 묶어서 계산하는 편이 좋을 것 같다.(군집화 진행)\n",
    "1) 모바일 게임\n",
    "2) 온라인 게임\n",
    "3) 모바일 / 온라인 게임\n",
    "- 각각에 게임 안에 카테고리 캐주얼, 슈팅 등등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc633e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100, 100))\n",
    "f, axes = plt.subplots(100, 10)\n",
    "# 격자 크기 설정\n",
    "f.set_size_inches((300, 300))\n",
    "# 격자 여백 설정\n",
    "plt.subplots_adjust(wspace = 0.2, hspace = 0.2)\n",
    "\n",
    "x = 0;\n",
    "y = 0;\n",
    "\n",
    "for num in (range(0,1000)):\n",
    "    axes[y][x].plot(df[(df[\"product_id\"] == num)].start_date, df[(df[\"product_id\"] == num)].revenue)\n",
    "    x = x + 1\n",
    "    if x == 10:\n",
    "        y = y + 1\n",
    "        x = 0\n",
    "\n",
    "#plt.show()\n",
    "plt.savefig(r'C:\\Users\\heygu\\savefig_default.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ef32d4",
   "metadata": {},
   "source": [
    "### 게임별 주간 매출액 합 비교\n",
    "- 기간 결측치를 고려해서 평균값으로 선정, 합으로 할 경우 결측치로 인해서 심하게 차이남\n",
    "- 게임별로 매출액의 차이가 크므로 지점별로 모델을 만들어 따로 예측을 해줘야겠다는 생각."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e7ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_max_store_sum = df.groupby('product_id')[['revenue']].mean()\n",
    "fig = plt.figure(figsize = (20,12))\n",
    "sns.barplot(x=train_max_store_sum.index, y=train_max_store_sum['revenue'], data=df)\n",
    "plt.title('Weekly_sales by store(sum)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8730893f",
   "metadata": {},
   "source": [
    "### 게임별 매출액과 변수들의 상관관계 확인\n",
    "- 1000개를 range를 조정해서 여러번 확인해 본 결과\n",
    "- 그래프 상에 게임별 변수들의 관계가 같지는 않음.\n",
    "- 물론 일정 부분 download, install_base, open_rate, total_active_days, total_time 이 많은 영향을 대체적으로 주지만 그게 모든 제품에 통용되지 않는 것이 그래프 상에 보임\n",
    "- 하지만 분명히 일정 게임들은 공통된 상관관계를 가지고 있는 것이 시각적으로 보인다.\n",
    "- 게임별 혹은 그룹별 모델링의 필요성이 느껴짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = []\n",
    "for num in range(0,50):\n",
    "    co = df[df.product_id==num]\n",
    "    co = co.reset_index()\n",
    "    num_corr = co.corr(method='spearman',numeric_only=True)['revenue']\n",
    "    num_corr = num_corr.drop(['product_id','revenue', 'start_Year', 'start_Month', 'start_Day', 'strart_WeekOfYear'])\n",
    "    corr.append(num_corr)\n",
    "corr_df = pd.concat(corr, axis=1).T\n",
    "corr_df.index = list(range(0,50))\n",
    "f, ax = plt.subplots(figsize=(30,15))\n",
    "plt.title(\"게임별 매출액과 변수들간의 상관관계\", fontsize=15)\n",
    "sns.heatmap(corr_df.T, cmap=sns.diverging_palette(240,10,as_cmap=True), ax=ax, annot = True)\n",
    "plt.xlabel('게임(id)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bdd1ea",
   "metadata": {},
   "source": [
    "\n",
    "* 또한 실제 도메인 지식을 기반으로 정리한 결과 유의미한 변수 관계라는 판단이 들었다.\n",
    "\n",
    "이를 통해서 각 변수간의 상관관계가 높은 것들을 추려 낼 수 있었다.\n",
    "상관성이 높다고 해서 무조건 유의미 하지는 않으므로 주의해야한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152c5e6f",
   "metadata": {},
   "source": [
    " ### 정규성 검정\n",
    " - 귀무가설 : 해당 데이터가 정규성을 충족한다.\n",
    "- 특징 : data수가 5000을 초과하는 경우, 정규성 검정에 대한 P 값을 담보하지 못한다. (즉, 통계적 유의성이 떨어진다.)\n",
    "- 0.05 이상이어야 유의하다.\n",
    "- 0.05 보다 작다.\n",
    "- 대부분의 값이 정규성을 띄고 있지 않음\n",
    "- 정규성이 없기에 비선형적 관계일 가능성이 크기에 method='spearman' 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd051def",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "shapiro_test, p_val = stats.shapiro(df_stand[\"average_active_days\"])\n",
    "print(\"Test-statistis:{}, p-value:{}\".format(shapiro_test, p_val))\n",
    "shapiro_test, p_val = stats.shapiro(df_stand[\"average_active_users\"])\n",
    "print(\"Test-statistis:{}, p-value:{}\".format(shapiro_test, p_val))\n",
    "shapiro_test, p_val = stats.shapiro(df_stand[\"average_session_duration\"])\n",
    "print(\"Test-statistis:{}, p-value:{}\".format(shapiro_test, p_val))\n",
    "shapiro_test, p_val = stats.shapiro(df_stand[\"average_time_per_user\"])\n",
    "print(\"Test-statistis:{}, p-value:{}\".format(shapiro_test, p_val))\n",
    "shapiro_test, p_val = stats.shapiro(df_stand[\"download\"])\n",
    "print(\"Test-statistis:{}, p-value:{}\".format(shapiro_test, p_val))\n",
    "shapiro_test, p_val = stats.shapiro(df_stand[\"install_base\"])\n",
    "print(\"Test-statistis:{}, p-value:{}\".format(shapiro_test, p_val))\n",
    "shapiro_test, p_val = stats.shapiro(df_stand[\"open_rate\"])\n",
    "print(\"Test-statistis:{}, p-value:{}\".format(shapiro_test, p_val))\n",
    "shapiro_test, p_val = stats.shapiro(df_stand[\"revenue\"])\n",
    "print(\"Test-statistis:{}, p-value:{}\".format(shapiro_test, p_val))\n",
    "shapiro_test, p_val = stats.shapiro(df_stand[\"total_active_days\"])\n",
    "print(\"Test-statistis:{}, p-value:{}\".format(shapiro_test, p_val))\n",
    "shapiro_test, p_val = stats.shapiro(df_stand[\"total_time\"])\n",
    "print(\"Test-statistis:{}, p-value:{}\".format(shapiro_test, p_val))\n",
    "shapiro_test, p_val = stats.shapiro(df_stand[\"genre\"])\n",
    "print(\"Test-statistis:{}, p-value:{}\".format(shapiro_test, p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4980a5",
   "metadata": {},
   "source": [
    "### 게임 중 90주 이상 데이터가 쌓인 게임 추세만 확인하기\n",
    "- 90주 이상도 마찬가지로 상당히 게임별로 추세가 다름\n",
    "- 이걸로 보다 확실히 게임별 혹은 그룹화에 이유가 생김"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c115ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(columns = df.columns)\n",
    "cnt = 90\n",
    "for num in range(0,1000):\n",
    "    co = df[(df[\"product_id\"] == num)]\n",
    "    size = co.count()\n",
    "    if size.start_date >= cnt:\n",
    "        print(co.count(), num)\n",
    "        df2 = pd.concat([df2,co], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3169067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = df2[['product_id']]\n",
    "name = name.drop_duplicates()\n",
    "name.reset_index(inplace=True)\n",
    "name = name.drop(columns='index')\n",
    "name['product_id'][0]\n",
    "number = df2.start_date.count()/cnt\n",
    "number\n",
    "name.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52832209",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 100))\n",
    "f, axes = plt.subplots(int(number/5 + 1), 5)\n",
    "# 격자 크기 설정\n",
    "f.set_size_inches((50, 50))\n",
    "# 격자 여백 설정\n",
    "plt.subplots_adjust(wspace = 0.2, hspace = 0.2)\n",
    "\n",
    "x = 0;\n",
    "y = 0;\n",
    "\n",
    "for num in (range(0,name['product_id'].count())):\n",
    "    axes[y][x].plot(df2[(df2[\"product_id\"] == name['product_id'][num])].start_date, df2[(df2[\"product_id\"] == name['product_id'][num])].revenue)\n",
    "    x = x + 1\n",
    "    if x == 5:\n",
    "        y = y + 1\n",
    "        x = 0\n",
    "\n",
    "#plt.show()\n",
    "plt.savefig(r'C:\\Users\\heygu\\savefig_default.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c1cde",
   "metadata": {},
   "source": [
    "### 게임 중 90주 이상 데이터가 쌓인 연도별 추세 \n",
    "- 90주 이상도 마찬가지로 게임별로 연도별 추세가 비슷한 것이 있고 없는 것이 있다.\n",
    "- 이걸로 보다 확실히 게임별 혹은 그룹화에 이유가 생김\n",
    "- 그래프를 보니 전년도에 급 상승하고 내년에는 상승없이 하락세인게 모바일 확률이 높다. 년도간 경향이 비슷한 애들이 온라인일 확률이 높을 거라 예상한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dc2b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30,60))\n",
    "\n",
    "for store in range(0,name['product_id'].count()):\n",
    "    storeset = df2[(df2[\"product_id\"] == name['product_id'][store])]\n",
    "    storeset_2021 = storeset[storeset.end_Year==2021]\n",
    "    storeset_2022 = storeset[storeset.end_Year==2022]\n",
    "    \n",
    "    ax = fig.add_subplot(int(number/5 + 1), 5, store + 1)\n",
    "    \n",
    "    plt.title(f\"store_{store}\")\n",
    "    ax.plot(storeset_2021.end_WeekOfYear, storeset_2021.revenue, label=\"2021\", alpha=0.3)\n",
    "    ax.plot(storeset_2022.end_WeekOfYear, storeset_2022.revenue, label=\"2022\", alpha=0.3)\n",
    "    ax.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5d3a17",
   "metadata": {},
   "source": [
    "### 게임 중 90주 이상 데이터에서의 변수간 상관관계\n",
    "- 마찬가지로 데이터가 다소 완전하더라도 모든 게임별 변수간 상관관계가 일치하지는 않는다.\n",
    "- 다소 download, install_base, open_rate, total_active_days, total_time 양의 상관관계를 자주 보여 주지만 그렇지 않은 게임도 다수 존재하는 편이다. \n",
    "- 그룹화에 필요성이 느껴진다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa405770",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = []\n",
    "for num in range(0,name['product_id'].count()):\n",
    "    co = df[df.product_id==name['product_id'][num]]\n",
    "    co = co.reset_index()\n",
    "    num_corr = co.corr(method='spearman', numeric_only=True)['revenue']\n",
    "    num_corr = num_corr.drop(['index','revenue', 'start_Year', 'start_Month', 'start_Day', 'strart_WeekOfYear'])\n",
    "    corr.append(num_corr)\n",
    "corr_df = pd.concat(corr, axis=1).T\n",
    "corr_df.index = list(range(0,name['product_id'].count()))\n",
    "f, ax = plt.subplots(figsize=(30,15))\n",
    "plt.title(\"게임별 매출액과 변수들간의 상관관계\", fontsize=15)\n",
    "sns.heatmap(corr_df.T, cmap=sns.diverging_palette(240,10,as_cmap=True), ax=ax, annot = True)\n",
    "plt.xlabel('게임(id)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a327d3b9",
   "metadata": {},
   "source": [
    "### Box Plot\n",
    "- 이상치 확인\n",
    "- 상당히 이상치가 많게 느껴짐\n",
    "- 이거는 게임별 특성을 고려하지 않은 상태에서 체크한 것이므로 그룹화후 다시 확인하겠음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cea0933",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "col_list = list(['average_active_days', 'average_active_users', \n",
    "                     'average_session_duration', 'average_session_per_user', 'average_time_per_user', 'total_active_days', 'total_time', 'download', 'install_base', 'open_rate', 'genre','revenue'])\n",
    "for column in col_list:\n",
    "    fig = plt.figure(figsize=(20,5))\n",
    "    sns.boxplot(x = df[column], color='yellow')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ecbc06",
   "metadata": {},
   "source": [
    "## 게임별 특성에 따른 그룹화 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fa5947",
   "metadata": {},
   "source": [
    "### 시계열 기준으로 1차 그룹화\n",
    "- 최소 50개 이상의 값이 존재하는 경우 그룹화 수행(추세가 보여야 그룹화 가능)\n",
    "- 앞에서 채워야함 . 보간법 채택이요 경향이나 추세가 사라지기 원하지 않음\n",
    "- 온라인 모바일에 경우 시각적으로 보이는 경향이 존재했기에\n",
    "- 시계열(Time Series) 데이터나 연속된 수치를 가지는 데이터의 경우에는 우리는 일종의 연속성있는 패턴을 발견할 수 있습니다. 이런 경우 보간(Interpolation)을 통해 앞,뒤 값을 통하여 유추하여 좀 더 스마트하게 결측치(NaN)를 채워줄 수 있습니다.\n",
    "- 하지만 게임산업에 특성상 잦은 이벤트나 각종 사건에 굉장히 예민하고 튀는 값들이 굉장히 많습니다. 기존적으로 추세만 봐도 그걸 느낄 수 있습니다. 그래서 그냥 중앙값으로 하는 것이 극단치에 영향을 덜 받을 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80554e50",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m      2\u001b[0m cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1000\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame(columns = df.columns)\n",
    "cnt = 80\n",
    "for num in range(0,1000):\n",
    "    co = df[(df[\"product_id\"] == num)]\n",
    "    #co = df[(df[\"product_id\"] == num)&(df[\"end_Year\"] == 2021)]\n",
    "    size = co.count()\n",
    "    if size.start_date >= cnt:\n",
    "        print(co.count(), num)\n",
    "        df2 = pd.concat([df2,co], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aae8763",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = df2[['product_id']]\n",
    "name = name.drop_duplicates()\n",
    "name.reset_index(inplace=True)\n",
    "name = name.drop(columns='index')\n",
    "name['product_id'][0]\n",
    "number = df2.start_date.count()/cnt\n",
    "number\n",
    "name.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "874e9887",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] 지정된 모듈을 찾을 수 없습니다. Error loading \"C:\\Users\\heygu\\anaconda3\\Lib\\site-packages\\torch\\lib\\caffe2_nvrtc.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtslearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimeSeriesKMeans\n\u001b[0;32m      3\u001b[0m scaled_time_series_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, name[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcount()) :\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# test 셋은 2022년 10월 데이터이기 때문에 각 연도별 10월(포함) 이전의 시계열 데이터의 유사성을 판단하여 type을 나누었습니다.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tslearn\\clustering\\__init__.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`tslearn.clustering` module gathers time series specific clustering\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03malgorithms.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m details.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkshape\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KShape\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (EmptyClusterError, silhouette_score,\n\u001b[0;32m     10\u001b[0m                     TimeSeriesCentroidBasedClusteringMixin)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkmeans\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (TimeSeriesKMeans, KernelKMeans)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tslearn\\clustering\\kshape.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_array\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_is_fitted\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtslearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimeSeriesScalerMeanVariance\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtslearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_time_series_dataset, check_dims\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtslearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cdist_normalized_cc, y_shifted_sbd_vec\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tslearn\\preprocessing\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`tslearn.preprocessing` module gathers time series scalers and \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mresamplers.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     TimeSeriesScalerMeanVariance,\n\u001b[0;32m      8\u001b[0m     TimeSeriesScalerMinMax,\n\u001b[0;32m      9\u001b[0m     TimeSeriesResampler\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimeSeriesResampler\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimeSeriesScalerMinMax\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimeSeriesScalerMeanVariance\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tslearn\\preprocessing\\preprocessing.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpolate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interp1d\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtslearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (to_time_series_dataset, check_equal_size, ts_size,\n\u001b[0;32m      9\u001b[0m                            check_dims)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtslearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimeSeriesBaseEstimator\n\u001b[0;32m     12\u001b[0m __author__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRomain Tavenard romain.tavenard[at]univ-rennes2.fr\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tslearn\\utils\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`tslearn.utils` module includes various utilities.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     check_dims,\n\u001b[0;32m      7\u001b[0m     check_equal_size,\n\u001b[0;32m      8\u001b[0m     to_time_series,\n\u001b[0;32m      9\u001b[0m     to_time_series_dataset,\n\u001b[0;32m     10\u001b[0m     time_series_to_str,\n\u001b[0;32m     11\u001b[0m     timeseries_to_str,\n\u001b[0;32m     12\u001b[0m     str_to_time_series,\n\u001b[0;32m     13\u001b[0m     str_to_timeseries,\n\u001b[0;32m     14\u001b[0m     save_time_series_txt,\n\u001b[0;32m     15\u001b[0m     save_timeseries_txt,\n\u001b[0;32m     16\u001b[0m     load_time_series_txt,\n\u001b[0;32m     17\u001b[0m     load_timeseries_txt,\n\u001b[0;32m     18\u001b[0m     ts_size,\n\u001b[0;32m     19\u001b[0m     ts_zeros,\n\u001b[0;32m     20\u001b[0m     check_dataset,\n\u001b[0;32m     21\u001b[0m     LabelCategorizer,\n\u001b[0;32m     22\u001b[0m     _load_txt_uea,\n\u001b[0;32m     23\u001b[0m     _load_arff_uea\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcast\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     to_sklearn_dataset,\n\u001b[0;32m     28\u001b[0m     from_cesium_dataset, to_cesium_dataset,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     from_tsfresh_dataset, to_tsfresh_dataset\n\u001b[0;32m     35\u001b[0m )\n\u001b[0;32m     39\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_dims\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_equal_size\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_time_series\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_time_series_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_tsfresh_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_tsfresh_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tslearn\\utils\\utils.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:  \u001b[38;5;66;03m# Old sklearn versions\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimator_checks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NotAnArray\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtslearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m instantiate_backend\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtslearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimeSeriesBaseEstimator\n\u001b[0;32m     23\u001b[0m __author__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRomain Tavenard romain.tavenard[at]univ-rennes2.fr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tslearn\\backend\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`tslearn.backend` module provides multiple backends.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThe backends provided are NumPy and PyTorch.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Backend, instantiate_backend, select_backend\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBackend\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstantiate_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tslearn\\backend\\backend.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtslearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy_backend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NumPyBackend\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtslearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_backend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PyTorchBackend\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:139\u001b[0m\n\u001b[0;32m    137\u001b[0m                 err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(ctypes\u001b[38;5;241m.\u001b[39mget_last_error())\n\u001b[0;32m    138\u001b[0m                 err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 139\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    141\u001b[0m     kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder, lib_name):\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] 지정된 모듈을 찾을 수 없습니다. Error loading \"C:\\Users\\heygu\\anaconda3\\Lib\\site-packages\\torch\\lib\\caffe2_nvrtc.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "\n",
    "scaled_time_series_df = pd.DataFrame()\n",
    "\n",
    "for num in range(0, name['product_id'].count()) :\n",
    "    # test 셋은 2022년 10월 데이터이기 때문에 각 연도별 10월(포함) 이전의 시계열 데이터의 유사성을 판단하여 type을 나누었습니다.\n",
    "    time_series = df[(df.product_id==name['product_id'][num])&(df.end_Year==2021)]['revenue'].values.reshape(-1, 1)\n",
    "    scaled_time_series = pd.DataFrame(time_series)\n",
    "    scaled_time_series_df[name['product_id'][num]] = scaled_time_series\n",
    "    scaled_time_series_df.loc[scaled_time_series_df[col_name] != scaled_time_series_df[col_name], col_name] = scaled_time_series_df[col_name].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c44208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose_scaled_time_series_df = scaled_time_series_df.transpose()\n",
    "    \n",
    "km = TimeSeriesKMeans(n_clusters=3, \n",
    "                      metric=\"dtw\", \n",
    "                      max_iter=5,\n",
    "                      random_state=2022)\n",
    "\n",
    "prediction = km.fit_predict(transpose_scaled_time_series_df)\n",
    "\n",
    "list_0 = []\n",
    "list_1 = []\n",
    "list_2 = []\n",
    "list_3 = []\n",
    "list_4 = []\n",
    "list_5 = []\n",
    "\n",
    "for i in range(len(prediction)) :\n",
    "    if prediction[i] == 0 :\n",
    "        list_0.append(name[\"product_id\"][i])\n",
    "    elif prediction[i] == 1 :\n",
    "        list_1.append(name[\"product_id\"][i])\n",
    "    elif prediction[i] == 2:\n",
    "        list_2.append(name[\"product_id\"][i])\n",
    "    elif prediction[i] == 3:\n",
    "        list_3.append(name[\"product_id\"][i])\n",
    "    elif prediction[i] == 4:\n",
    "        list_4.append(name[\"product_id\"][i])\n",
    "    else:\n",
    "        list_5.append(name[\"product_id\"][i])\n",
    "\n",
    "print(\"Clustering 0 : \", list_0)\n",
    "print(\"Clustering 1 : \", list_1)\n",
    "print(\"Clustering 2 : \", list_2)\n",
    "print(\"Clustering 3 : \", list_3)\n",
    "print(\"Clustering 4 : \", list_4)\n",
    "print(\"Clustering 5 : \", list_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166b25e4",
   "metadata": {},
   "source": [
    "#### 그룹화된 게임별 추세 비교 \n",
    "- 연도별 비교\n",
    "- 전체 추세 비교\n",
    "- 80개에 데이터가 남아있는 게임을 클러스터링 \n",
    "- 3개로 클러스터링 : 가장 분배가 적절한 결과를 보였기 때문에\n",
    " (너무 지나치게 세분화되어 1개-2개씩 남는 경우는 배제 하였다. 이유는 그런 경우 모델링 시 과적합 우려가 되기 때문이다.)\n",
    " - 기준을 모바일적 성향에 게임의 그래프가 어느정도 분리되는 시점으로 클러스터링 갯수를 잡음\n",
    " <br>\n",
    " - 다시한번 분배해서 살펴보니 2가지 성향이 눈에 띄었는제 하나는 급격히 상승했다가 낮아지는 모바일 게임 곡선\n",
    " - 년도별 비슷한 추세를 나타내는 온라인 게임 성향이 보였다.\n",
    " \n",
    " <br>확실히 앞에 년도가 중요성이 크다. 앞에 년도가 40개 이상 남은 애들로 클러스터링을 시도하자.굉장히 앞년도를 비슷하게 분류했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de533ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "new2 = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(list_2)) :\n",
    "    new = pd.DataFrame()\n",
    "    new[\"revenue\"] = scaled_time_series_df[list_2[i]]\n",
    "    new[\"product_id\"] = list_2[i]\n",
    "    df_new = df[(df[\"product_id\"] == 13)][\"end_Year\"]\n",
    "    df_new = df_new.reset_index()\n",
    "    new[\"end_Year\"] = df_new[\"end_Year\"]\n",
    "    df_new = df[(df[\"product_id\"] == 13)][\"end_WeekOfYear\"]\n",
    "    df_new = df_new.reset_index()\n",
    "    new[\"end_WeekOfYear\"] = df_new[\"end_WeekOfYear\"]\n",
    "    new2 = pd.concat([new2,new], axis=0)\n",
    "    \n",
    "#new2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac867da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,30))\n",
    "\n",
    "for num in range(0,len(list_2)):\n",
    "    storeset = new2[new2['product_id'] == list_2[num]]\n",
    "    storeset_2021 = storeset[storeset.end_Year==2021]\n",
    "    storeset_2022 = storeset[storeset.end_Year==2022]\n",
    "    \n",
    "    ax = fig.add_subplot(20,11, num+ 1)\n",
    "    \n",
    "    plt.title(f\"store_{num}\")\n",
    "    ax.plot(storeset_2021.end_WeekOfYear, storeset_2021.revenue, label=\"2021\", alpha=0.3)\n",
    "    ax.plot(storeset_2022.end_WeekOfYear, storeset_2022.revenue, label=\"2022\", alpha=0.3)\n",
    "    ax.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2aa721",
   "metadata": {},
   "source": [
    "#### 그래프 겹쳐서 확인\n",
    "- 앞에 2021년도 값이 40개 이상일때 가장 잘 클러스터링 됨\n",
    "- 시간은 흐름이 중요한데 끊겨서 많은 것보다는 연속적인 시간의 흐름 값이 중요한 듯하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae50823",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30,30))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig2, ax2 = plt.subplots()\n",
    "\n",
    "\n",
    "for num in range(0,len(list_0)):\n",
    "    storeset = new2[new2['product_id'] == list_0[num]]\n",
    "    storeset_2021 = storeset[storeset.end_Year==2021]\n",
    "    storeset_2022 = storeset[storeset.end_Year==2022]\n",
    "    \n",
    "    #ax = fig.add_subplot(20,11, num + 1)\n",
    "    \n",
    "   # plt.title(f\"store_{num}\")\n",
    "    ax.plot(storeset_2021.end_WeekOfYear, storeset_2021.revenue, label=\"2021\", alpha=0.3)\n",
    "    ax2.plot(storeset_2022.end_WeekOfYear, storeset_2022.revenue, label=\"2022\", alpha=0.3)\n",
    "    #ax.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b0111e",
   "metadata": {},
   "source": [
    "### 시계열 기준으로 1차 그룹화\n",
    "- 이유: 그래프가 겹치는 부분이 유사성과 관련해서는 그룹화가 되는 듯 보이나. 전체적인 추세를 제대로 반영하여 클러스터링이 된는 것 같지 않다.\n",
    "- 연도별로 클러스터링을 진행해서 결측치에 대해서도 어느정도 회피해보려한다.\n",
    "\n",
    "- 2021년 기준 클러스터링 (1년 52주로해서 40주 이상인 게임이 441개로 절반 정도 존재) \n",
    "- 2022년 기준 클러스터링 : 40주 이상인 값이 129개 밖에 안됨 클러스터링 하기에는 너무 적다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e04aa71",
   "metadata": {},
   "source": [
    "#### 2021그룹화\n",
    "- 2 - 3개가 적당하다 그 이상은 1-2개로 남는 경우가 생겨 과적합 우려가 있다. 특성을 너무 자세히 나눔\n",
    "- 2개를 나누었을때 모바일 적 성향에 친구와 온라인 성향에 게임이 나눠어진 경향이 있었다.\n",
    "- 다소 비슷한게 클러스터링 되었다.\n",
    "- 그만큼 2021년도의 전반적인 추세의 중요성이 입증되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cce224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(columns = df.columns)\n",
    "cnt = 40\n",
    "for num in range(0,1000):\n",
    "    #co = df[(df[\"product_id\"] == num)&(df[\"end_Year\"] == 2021)]\n",
    "    co = df[(df[\"product_id\"] == num)&(df[\"end_Year\"] == 2022)]\n",
    "    size = co.count()\n",
    "    if size.start_date >= cnt:\n",
    "        df2 = pd.concat([df2,co], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf08406",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = df2[['product_id']]\n",
    "name = name.drop_duplicates()\n",
    "name.reset_index(inplace=True)\n",
    "name = name.drop(columns='index')\n",
    "number = df2.start_date.count()/cnt\n",
    "number\n",
    "name.count()\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f15ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "\n",
    "scaled_time_series_df = pd.DataFrame()\n",
    "\n",
    "for num in range(0, name['product_id'].count()) :\n",
    "    col_name = \"Game \" +str(num)\n",
    "    time_series = df[(df.product_id==name['product_id'][num])&(df[\"end_Year\"] == 2021)]['revenue'].values.reshape(-1, 1)\n",
    "    scaled_time_series = pd.DataFrame(time_series)\n",
    "    scaled_time_series_df[name['product_id'][num]] = scaled_time_series\n",
    "    scaled_time_series_df.loc[scaled_time_series_df[name['product_id'][num]] != scaled_time_series_df[name['product_id'][num]], name['product_id'][num]] = scaled_time_series_df[name['product_id'][num]].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf9ea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose_scaled_time_series_df = scaled_time_series_df.transpose()\n",
    "    \n",
    "km = TimeSeriesKMeans(n_clusters=2, \n",
    "                      metric=\"dtw\", \n",
    "                      max_iter=10,\n",
    "                      random_state=0\n",
    "                     ,n_jobs=-1)\n",
    "\n",
    "prediction = km.fit_predict(transpose_scaled_time_series_df)\n",
    "\n",
    "list_0 = []\n",
    "list_1 = []\n",
    "list_2 = []\n",
    "list_3 = []\n",
    "list_4 = []\n",
    "list_5 = []\n",
    "\n",
    "for i in range(len(prediction)) :\n",
    "    if prediction[i] == 0 :\n",
    "        list_0.append(name[\"product_id\"][i])\n",
    "    elif prediction[i] == 1 :\n",
    "        list_1.append(name[\"product_id\"][i])\n",
    "    elif prediction[i] == 2:\n",
    "        list_2.append(name[\"product_id\"][i])\n",
    "    elif prediction[i] == 3:\n",
    "        list_3.append(name[\"product_id\"][i])\n",
    "    elif prediction[i] == 4:\n",
    "        list_4.append(name[\"product_id\"][i])\n",
    "    else:\n",
    "        list_5.append(name[\"product_id\"][i])\n",
    "\n",
    "print(\"Clustering 0 : \", list_0)\n",
    "print(\"Clustering 1 : \", list_1)\n",
    "print(\"Clustering 2 : \", list_2)\n",
    "print(\"Clustering 3 : \", list_3)\n",
    "print(\"Clustering 4 : \", list_4)\n",
    "print(\"Clustering 5 : \", list_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76de57fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "new2 = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(list_1)) :\n",
    "    new = pd.DataFrame()\n",
    "    new[\"revenue\"] = scaled_time_series_df[list_1[i]]\n",
    "    new[\"product_id\"] = list_1[i]\n",
    "    df_new = df[(df[\"product_id\"] == 13)][\"end_Year\"]\n",
    "    df_new = df_new.reset_index()\n",
    "    new[\"end_Year\"] = df_new[\"end_Year\"]\n",
    "    df_new = df[(df[\"product_id\"] == 13)][\"end_WeekOfYear\"]\n",
    "    df_new = df_new.reset_index()\n",
    "    new[\"end_WeekOfYear\"] = df_new[\"end_WeekOfYear\"]\n",
    "    new2 = pd.concat([new2,new], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c785044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30,30))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for num in range(0,len(list_0)):\n",
    "    storeset = new2[new2['product_id'] == list_0[num]]\n",
    "    storeset_2021 = storeset[storeset.end_Year==2021]\n",
    "   # storeset_2022 = storeset[storeset.end_Year==2022]\n",
    "    \n",
    "    #ax = fig.add_subplot(20,11, num + 1)\n",
    "    \n",
    "    #plt.title(f\"store_{num}\")\n",
    "    ax.plot(storeset_2021.end_WeekOfYear, storeset_2021.revenue, label=\"2021\", alpha=0.3)\n",
    "   # ax.plot(storeset_2022.end_WeekOfYear, storeset_2022.revenue, label=\"2022\", alpha=0.3)\n",
    "    #ax.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e617b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30,30))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for num in range(0,len(list_1)):\n",
    "    storeset = new2[new2['product_id'] == list_1[num]]\n",
    "    storeset_2021 = storeset[storeset.end_Year==2021]\n",
    "   # storeset_2022 = storeset[storeset.end_Year==2022]\n",
    "    \n",
    "    #ax = fig.add_subplot(20,11, num + 1)\n",
    "    \n",
    "    #plt.title(f\"store_{num}\")\n",
    "    ax.plot(storeset_2021.end_WeekOfYear, storeset_2021.revenue, label=\"2021\", alpha=0.3)\n",
    "   # ax.plot(storeset_2022.end_WeekOfYear, storeset_2022.revenue, label=\"2022\", alpha=0.3)\n",
    "    #ax.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4abf113",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30,30))\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "\n",
    "for num in range(0,len(list_0)):\n",
    "    storeset = new2[new2['product_id'] == list_0[num]]\n",
    "    storeset_2021 = storeset[storeset.end_Year==2021]\n",
    "    storeset_2022 = storeset[storeset.end_Year==2022]\n",
    "    \n",
    "    ax = fig.add_subplot(15,10, num + 1)\n",
    "    \n",
    "    #plt.title(f\"store_{num}\")\n",
    "    ax.plot(storeset_2021.end_WeekOfYear, storeset_2021.revenue, label=\"2021\", alpha=0.3)\n",
    "    ax.plot(storeset_2022.end_WeekOfYear, storeset_2022.revenue, label=\"2022\", alpha=0.3)\n",
    "    ax.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683b5777",
   "metadata": {},
   "source": [
    "### 최종 결정\n",
    "- 앞에 주기는 30이상이고 전체 주는 70이상인 값 / 60 , 30 /전체 40개\n",
    "- 확실히 데이터가 많을 수록 좋음\n",
    "- 클러스터링은 2 - 3개로 확정\n",
    "- 가장 잘 그래프 상 추세를 분리함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ae17e6",
   "metadata": {},
   "source": [
    "## 그룹화 잘 분배 되었는지 검증\n",
    "- 2가지 경우(전체 그룹화 / 2021년만 그룹화)\n",
    "- 상관관계 분석하기\n",
    "- 상자그림 \n",
    "- 산점도 분석\n",
    "- 시계열 분해해서 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff69d12",
   "metadata": {},
   "source": [
    "### 그룹별 상자그림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1eacaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "col_list = list(['average_active_days', 'average_active_users', \n",
    "\n",
    "                 'average_session_duration', 'average_session_per_user', 'average_time_per_user', 'total_active_days', 'total_time', 'download', 'install_base', 'open_rate', 'genre','revenue'])\n",
    "\n",
    "df_box = df[(df[\"Type\"]==0)]\n",
    "\n",
    "for column in col_list:\n",
    "    fig = plt.figure(figsize=(20,5))\n",
    "    sns.boxplot(x = df_box[column], color='yellow')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03832378",
   "metadata": {},
   "source": [
    "### 그룹별 상관관계\n",
    "- 그룹별 상관관계\n",
    "- 그룹화한 게임별 상관관계\n",
    "- 그룹화한 연도별 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1bc32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = []\n",
    "for num in range(0,3):\n",
    "    co = df[df.Type==num]\n",
    "    co = co.reset_index()\n",
    "    num_corr = co.corr(method='spearman')['revenue']\n",
    "    num_corr = num_corr.drop(['index','revenue', 'start_Year', 'start_Month', 'start_Day', 'strart_WeekOfYear'])\n",
    "    corr.append(num_corr)\n",
    "corr_df = pd.concat(corr, axis=1).T\n",
    "corr_df.index = list(range(0,3))\n",
    "f, ax = plt.subplots(figsize=(30,15))\n",
    "plt.title(\"게임별 매출액과 변수들간의 상관관계\", fontsize=15)\n",
    "sns.heatmap(corr_df.T, cmap=sns.diverging_palette(240,10,as_cmap=True), ax=ax, annot = True)\n",
    "plt.xlabel('게임(id)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b5781",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = []\n",
    "lentgh = 0\n",
    "for num in range(0,100):\n",
    "    co = df[(df.Type==0)&(df.product_id==num)]\n",
    "    if len(co) > 0:\n",
    "        lentgh = lentgh + 1\n",
    "        co = co.reset_index()\n",
    "        num_corr = co.corr(method='spearman')['revenue']\n",
    "        num_corr = num_corr.drop(['index','revenue', 'start_Year', 'start_Month', 'start_Day', 'strart_WeekOfYear'])\n",
    "        corr.append(num_corr)\n",
    "    \n",
    "corr_df = pd.concat(corr, axis=1).T\n",
    "corr_df.index = list(range(0,lentgh))\n",
    "f, ax = plt.subplots(figsize=(30,15))\n",
    "plt.title(\"게임별 매출액과 변수들간의 상관관계\", fontsize=15)\n",
    "sns.heatmap(corr_df.T, cmap=sns.diverging_palette(240,10,as_cmap=True), ax=ax, annot = True)\n",
    "plt.xlabel('게임(id)')\n",
    "plt.show()\n",
    "\n",
    "lentgh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = []\n",
    "lentgh = 0\n",
    "for num in range(0,100):\n",
    "    co = df[(df.Type==0)&(df.end_Year==2021)]\n",
    "    if len(co) > 0:\n",
    "        lentgh = lentgh + 1\n",
    "        co = co.reset_index()\n",
    "        num_corr = co.corr(method='spearman')['revenue']\n",
    "        num_corr = num_corr.drop(['index','revenue', 'start_Year', 'start_Month', 'start_Day', 'strart_WeekOfYear'])\n",
    "        corr.append(num_corr)\n",
    "    \n",
    "corr_df = pd.concat(corr, axis=1).T\n",
    "corr_df.index = list(range(0,lentgh))\n",
    "f, ax = plt.subplots(figsize=(30,15))\n",
    "plt.title(\"게임별 매출액과 변수들간의 상관관계\", fontsize=15)\n",
    "sns.heatmap(corr_df.T, cmap=sns.diverging_palette(240,10,as_cmap=True), ax=ax, annot = True)\n",
    "plt.xlabel('게임(id)')\n",
    "plt.show()\n",
    "\n",
    "lentgh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4358feb3",
   "metadata": {},
   "source": [
    "### 그룹별 산점도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5db775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid') # 배경을 하얗게 한다\n",
    "df_stand = df\n",
    "sns.pairplot(df_stand[['average_active_days', 'average_active_users', \n",
    "                     'average_session_duration', 'average_session_per_user', 'average_time_per_user', 'total_active_days', 'total_time', 'download', 'install_base', 'open_rate', 'genre', 'revenue']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101cdca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid') # 배경을 하얗게 한다\n",
    "\n",
    "df_stand = df[(df.Type==0)]\n",
    "\n",
    "sns.pairplot(df_stand[['average_active_days', 'average_active_users', \n",
    "                     'average_session_duration', 'average_session_per_user', 'average_time_per_user', 'total_active_days', 'total_time', 'download', 'install_base', 'open_rate', 'genre', 'revenue']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ae038e",
   "metadata": {},
   "source": [
    "## 그외 데이터분석에 도움이 될 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d10a4c",
   "metadata": {},
   "source": [
    "### 변수간 상관관계 분석으로 revenue에 Type 주는 영향 보기\n",
    "- 나름 영향을 주고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d63b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(28,14))\n",
    "plt.xticks( fontsize=20)\n",
    "plt.yticks( fontsize=20)\n",
    "temp = df[df.end_Year==2021]\n",
    "sns.heatmap(df.corr(method='spearman'), cmap='Reds', annot=True, annot_kws={'size':12})\n",
    "plt.title('Correlation Matrix only 2021', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1156252",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(28,14))\n",
    "plt.xticks(fontsize=20) \n",
    "plt.yticks(fontsize=20)\n",
    "temp = df[df.end_Year==2022]\n",
    "sns.heatmap(df.corr(method='spearman'), cmap='Reds', annot=True, annot_kws={'size':12})\n",
    "plt.title('Correlation Matrix only 2022', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aa8025",
   "metadata": {},
   "source": [
    "### 변수 특성 시각화\n",
    "- 게임별 매출액 비교\n",
    "- 시간에 따른 매출액 추이(달, 주)\n",
    "- 상관관계가 큰 변수들의 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84268cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by year\n",
    "df.groupby('end_Year')['revenue'].mean()\n",
    "# Group by month\n",
    "df.groupby('end_Month')['revenue'].mean()\n",
    "# Group by week\n",
    "df.groupby('end_WeekOfYear')['revenue'].mean()\n",
    "\n",
    "# Visualization by month\n",
    "monthly_sales = pd.pivot_table(df, values = \"revenue\", columns = \"end_Year\", index = \"end_Month\")\n",
    "monthly_sales.plot()\n",
    "\n",
    "fig = sns.barplot(x='end_Month', y='revenue', data=df)\n",
    "\n",
    "\n",
    "# Visualization by week\n",
    "weekly_sales = pd.pivot_table(df, values = \"revenue\", columns = \"end_Year\", index = \"end_WeekOfYear\")\n",
    "weekly_sales.plot()\n",
    "plt.figure(figsize=(70,6))\n",
    "fig = sns.barplot(x='end_WeekOfYear', y='revenue', data=df)\n",
    "\n",
    "# External variable check\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "fig = sns.barplot(x=\"Type\", y='revenue', data=df)\n",
    "\n",
    "fuel_price = pd.pivot_table(df, values = \"revenue\", index= \"total_active_days\")\n",
    "fuel_price.plot()\n",
    "\n",
    "\n",
    "unemployment = pd.pivot_table(df, values = \"revenue\", index= \"total_time\")\n",
    "unemployment.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8147ed",
   "metadata": {},
   "source": [
    "### 변수 추가\n",
    "- 유의성을 보고 부족해서 채운거임 (결과보고 부족해서)\n",
    "- 하루 매출\n",
    "- 유저 당 매출\n",
    "- 1주 2주, 3주,4주 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20669d32",
   "metadata": {},
   "source": [
    "#### 시계열 acf,pacf 분석\n",
    "- 1 ~ 4주 사이에 영향력이 강해 보임\n",
    "- 1 ~4주 매출액을 만들겠음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027529b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(df):\n",
    "    df_sum = {}\n",
    "    df_sum['revenue'] = df['revenue'].sum()\n",
    "    df_sum['total_active_days'] = df['total_active_days'].mean()\n",
    "    df_sum['total_time'] = df['total_time'].mean()\n",
    "    df_sum['average_time_per_user'] = df['average_time_per_user'].mean()\n",
    "    return pd.Series(df_sum, index=['revenue', 'total_active_days', \n",
    "                                    'total_time', 'average_time_per_user'])\n",
    "\n",
    "df_agg = df.groupby(['end_Year', 'end_date']).apply(func).reset_index()\n",
    "\n",
    "df_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436cf1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSeries_decomp = df_agg.loc[:, [\"end_date\",\"revenue\"]]\n",
    "timeSeries_decomp.index = timeSeries_decomp.end_date\n",
    "ts_decomp = timeSeries_decomp.drop(\"end_date\",axis=1)\n",
    "\n",
    "ts_decomp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6924e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp = seasonal_decompose(ts_decomp['revenue'], model='additive', period=4)\n",
    "\n",
    "fig = plt.figure()  \n",
    "fig = decomp.plot()  \n",
    "fig.set_size_inches(20, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0d7e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF, PACF 그래프 시각화\n",
    "\n",
    "fig = plt.figure(figsize=(20,8))\n",
    "ax1 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_acf(ts_decomp, lags=45, ax=ax1)\n",
    "\n",
    "ax2 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_pacf(ts_decomp, lags=45, ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94371ba4",
   "metadata": {},
   "source": [
    "#### 평균 매출 열 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0872718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Day_revenue\"] = df[\"revenue\"]/7\n",
    "df[\"user_revenue\"] = df[\"revenue\"]/df[\"average_active_users\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392b67a2",
   "metadata": {},
   "source": [
    "#### 1~4주전 열 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b854de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['revenue_1w'] = df['revenue'].groupby(df[\"product_id\"]).shift(1)\n",
    "df['revenue_2w'] = df['revenue'].groupby(df[\"product_id\"]).shift(2)\n",
    "df['revenue_3w'] = df['revenue'].groupby(df[\"product_id\"]).shift(3)\n",
    "df['revenue_4w'] = df['revenue'].groupby(df[\"product_id\"]).shift(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd105a6",
   "metadata": {},
   "source": [
    "## 전처리\n",
    "- 활성도 0인거 그거 확인해서 중앙값 넣어주기 오케?\n",
    "- 마지막으로 train, test 셋 나누어주기!\n",
    "- 변수, 데이터 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcd8c0d",
   "metadata": {},
   "source": [
    "### 로그변화\n",
    "- 왼쪽 긴꼬리 분포를 띄고 있다.\n",
    "- 매출이 치우쳐져 있다.\n",
    "- 로그처리하면 소수점 값들이 너무 많아서 그냥 정규분포를 따르도록 변환하려함\n",
    "- 하지만 애초에 필요가 없는듯..\n",
    "- 매출은 애초에 한쪽에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5551e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "sns.distplot(df['revenue'], fit=stats.norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb69e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log1p(df['revenue']), fit=stats.norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c7f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = []\n",
    "for num in range(50,100):\n",
    "    co = df[df.product_id==num]\n",
    "    co = co.reset_index()\n",
    "    num_corr = co.corr(method='spearman', numeric_only=True)['revenue']\n",
    "    num_corr = num_corr.drop(['product_id','revenue', 'start_Year', 'start_Month', 'start_Day', 'strart_WeekOfYear'])\n",
    "    corr.append(num_corr)\n",
    "corr_df = pd.concat(corr, axis=1).T\n",
    "corr_df.index = list(range(0,50))\n",
    "\n",
    "f, ax = plt.subplots(figsize=(30,15))\n",
    "plt.title(\"게임별 매출액과 변수들간의 상관관계\", fontsize=15)\n",
    "sns.heatmap(corr_df.T, cmap=sns.diverging_palette(240,10,as_cmap=True), ax=ax, annot = True)\n",
    "plt.xlabel('게임(id)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22925e85",
   "metadata": {},
   "source": [
    "### 표준화 필요성 여부 판단\n",
    "- 표준화 전과 후가 전혀 산점도 그래프와 상관관계 분석 결과에도 영향을 주지 않았다.\n",
    "- 이미 0 ~1 사이의 값으로 변환된 상태였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed041f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import pandas as pd\n",
    "\n",
    "df_stand = df[['average_active_days', 'average_active_users', \n",
    "                     'average_session_duration', 'average_session_per_user', 'average_time_per_user', 'total_active_days', 'total_time', 'download', 'install_base', 'open_rate', 'genre', 'revenue']]\n",
    "# 전체 컬럼 표준화\n",
    "\n",
    "# 데이터 표준화 적용\n",
    "StandardScaler = StandardScaler()\n",
    "df_stand2 = StandardScaler.fit_transform(df_stand)\n",
    "\n",
    "# 컬럼명 결합\n",
    "df_stand = pd.DataFrame(data=df_stand2, columns=df_stand.columns)\n",
    "\n",
    "df_new = df.drop(['average_active_days', 'average_active_users', \n",
    "                     'average_session_duration', 'average_session_per_user', 'average_time_per_user', 'total_active_days', 'total_time', 'download', 'install_base', 'open_rate', 'genre', 'revenue'], axis=1)\n",
    "\n",
    "df_stand = pd.concat([df_new, df_stand], axis=1)\n",
    "df_stand.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30d2a6d",
   "metadata": {},
   "source": [
    "# 모델링/학습\n",
    "1) GridSearch\n",
    "2) CatBoostRegressor\n",
    "3) LinearRegression 다중회귀모델 생성\n",
    "4) RandomForestRegressor\n",
    "5) STL-ETS\n",
    "6) XGBRegressor\n",
    "7) LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a79da7",
   "metadata": {},
   "source": [
    "## GridSearch\n",
    "\n",
    "Grid는 격자라는 뜻. 일정한 범위(격자)를 지정해주면, 범위 내의 모든 조합을 비교해서 내가 정한 Score를 기준으로 하이퍼파라미터값을 구해준다. 단, '모든' 조합을 비교하기 때문에 느리다. 대신에 정확하다. 범위를 넓게 잡으면? 당연히 오래 걸린다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db04269",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42145a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn import metrics, ensemble, linear_model\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb370a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train\n",
    "X_train = df[df.end_Month <= 10]\n",
    "y_train = X_train.revenue\n",
    "\n",
    "feature = ['total_time', 'average_time_per_user', 'average_session_duration','average_session_per_user', 'average_active_users', 'average_active_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34a502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "              'objective':['reg:squarederror'],\n",
    "              'learning_rate':[0.1], #so called `eta` value\n",
    "              'max_depth': [50],\n",
    "              'min_child_weight': [4],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.8],\n",
    "              'n_estimators':[30000]\n",
    "              } \n",
    "\n",
    "xgb = XGBRegressor(random_state = 2022)\n",
    "\n",
    "\n",
    "xgb_grid = GridSearchCV(estimator=xgb,\n",
    "                        param_grid =parameters,\n",
    "                        cv = 10,\n",
    "                        n_jobs=1,\n",
    "                        scoring = 'neg_mean_absolute_error',\n",
    "                        verbose=3,\n",
    "                        \n",
    "                        )\n",
    "\n",
    "xgb_grid.fit(X_train[feature], y_train)\n",
    "best_model = xgb_grid.best_estimator_\n",
    "\n",
    "print(\"BEST SCORE : {}\".format(xgb_grid.best_score_))\n",
    "print(\"BEST PARAMETER : {}\".format(xgb_grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f5b40",
   "metadata": {},
   "source": [
    "## CatBoost\n",
    "CatBoost는 그라디언트 부스팅 알고리즘을 기반으로 한 머신러닝 프레임워크입니다. CatBoost는 특히 시계열 데이터 처리에 탁월한 성능을 보여줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d01aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
